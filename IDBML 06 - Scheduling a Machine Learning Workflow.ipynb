{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a0506db9-6c00-4ad8-9453-6dd92100f802",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "d-sandbox\n",
    "\n",
    "<div style=\"text-align: center; line-height: 0; padding-top: 9px;\">\n",
    "  <img src=\"https://databricks.com/wp-content/uploads/2018/03/db-academy-rgb-1200px.png\" alt=\"Databricks Learning\" style=\"width: 600px\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "695234b8-7071-42d7-b4de-a1c87848bc3b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# IDBML 06 - Scheduling a Machine Learning Workflow\n",
    "\n",
    "<img src=\"https://s3.us-west-2.amazonaws.com/files.training.databricks.com/images/idbml/06-image.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "221dbc8b-30b9-4612-b54e-3540d2927f73",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Classroom Setup\n",
    "\n",
    "First, we'll run the `Classroom-Setup` notebook to set up our environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f1ee53c8-2831-4603-8468-1059a7877de1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run \"./Includes/Classroom-Setup\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b96faddd-53e8-47b8-870f-10a5eab70e92",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "-sandbox\n",
    "## Training Workflow\n",
    "\n",
    "In this notebook, we'll create a workflow to retrain our model. Then, we'll set up this notebook to run monthly using a Databricks Job to ensure our model is always up-to-date.\n",
    "\n",
    "### Load Features\n",
    "\n",
    "First, we'll load in our feature table.\n",
    "\n",
    "<img alt=\"Side Note\" title=\"Side Note\" style=\"vertical-align: text-bottom; position: relative; height:1.75em; top:0.05em; transform:rotate(15deg)\" src=\"https://files.training.databricks.com/static/images/icon-note.webp\"/> In the case of this demonstration, these are the same records &mdash; but in real-world scenario, we'd likely have updated records appended to this table each time the model is trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4ecb3016-f2b1-443c-a78f-65d03944c915",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from databricks.feature_store import FeatureStoreClient\n",
    "\n",
    "feature_table = f\"{database_name}.listings_features\"\n",
    "fs = FeatureStoreClient()\n",
    "features = fs.read_table(feature_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9c2c3819-96a4-431f-b23f-2b042624e388",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### AutoML Process\n",
    "\n",
    "Next, we'll use the AutoML API to kick off an AutoML regression experiment. This is similar to what we did with the AutoML UI, but we can use the API to automate this process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b1ef4c12-0429-488f-b44c-59d76539bb05",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import databricks.automl\n",
    "model = databricks.automl.regress(\n",
    "    features, \n",
    "    target_col=\"price\",\n",
    "    primary_metric=\"r2\",\n",
    "    timeout_minutes=5,\n",
    "    max_trials=10,\n",
    "    \n",
    ") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7fd3d132-164c-4c7d-9ad9-c7867e215b7e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Register the Best Model\n",
    "\n",
    "Once the AutoML experiment is done, we can identify the best model from the experiment and register that model to the Model Registry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "86188f63-8cf1-44bd-bc2a-eb7299a11a1a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from mlflow.tracking.client import MlflowClient\n",
    "\n",
    "client = MlflowClient()\n",
    "\n",
    "run_id = model.best_trial.mlflow_run_id\n",
    "model_name = \"idbml-airbnb-price\"\n",
    "model_uri = f\"runs:/{run_id}/model\"\n",
    "\n",
    "model_details = mlflow.register_model(model_uri, model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a3f5327b-fadd-436d-ba9e-a86851838246",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Request Transition to Staging\n",
    "\n",
    "Once the model is registered, we request that it be transitioned to the **Staging** stage for testing.\n",
    "\n",
    "First, we'll load in some helper functions from the **`./Includes/Registry-Helpers`** notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2f4c3b8a-399c-4bbe-8cdc-53a4fca5ed85",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ./Includes/Registry-Helpers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "be7a63c1-6775-46ec-a039-71668ea62445",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Next, we'll set up the transition request using the `mlflow_call_endpoint` operation from the helpers notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9ac13565-d30a-4df5-bda6-844b997141fa",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "staging_request = {'name': model_name, 'version': model_details.version, 'stage': 'Staging', 'archive_existing_versions': 'true'}\n",
    "mlflow_call_endpoint('transition-requests/create', 'POST', json.dumps(staging_request))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "70077a9b-4973-413a-a8b7-273805eb47de",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "And we'll add a comment to the version of the model that we just requested be moved to **Staging** to let the machine learning engineer know why we are making the request."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "79f851cd-516b-49c1-9942-cc1f1b88a50c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Leave a comment for the ML engineer who will be reviewing the tests\n",
    "comment = \"This was the best model from the most recent AutoML run. I think we can use it to update our workflow. Let's set it up for testing.\"\n",
    "comment_body = {'name': model_name, 'version': model_details.version, 'comment': comment}\n",
    "mlflow_call_endpoint('comments/create', 'POST', json.dumps(comment_body))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f4cb11e9-c5eb-4b67-aa2c-cbdb98fe85c9",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "-sandbox\n",
    "## Scheduling the Training Workflow\n",
    "\n",
    "Now that we've created our training workflow, we're going to schedule this notebook to run in a Databricks Job.\n",
    "\n",
    "### Creating a Databricks Job\n",
    "\n",
    "#### Step 1\n",
    "\n",
    "To create a Databricks Job, we want to start by clicking on the **Jobs** button in the sidebar.\n",
    "\n",
    "<img src=\"https://files.training.databricks.com/images/idbml/job-1.png\">\n",
    "\n",
    "#### Step 2\n",
    "\n",
    "Next, click on the **Create Job** button at the top of the page.\n",
    "\n",
    "<img src=\"https://files.training.databricks.com/images/idbml/job-2.png\">\n",
    "\n",
    "#### Step 3\n",
    "\n",
    "Third, we'll want to fill out the details of our job.\n",
    "\n",
    "In this case, we want to run this notebook on a Job cluster.\n",
    "\n",
    "Once we've filled out this form, we need to click the **Save** button.\n",
    "\n",
    "<img src=\"https://files.training.databricks.com/images/idbml/job-3.png\">\n",
    "\n",
    "#### Step 4\n",
    "\n",
    "And because we want the job to run monthly, we need to set up a schedule.\n",
    "\n",
    "Click the **No Schedule** button in the top-right corner of the page.\n",
    "\n",
    "Next, fill out the schedule form for your Job to run monthly.\n",
    "\n",
    "<img src=\"https://files.training.databricks.com/images/idbml/job-4.png\">\n",
    "\n",
    "#### Step 5\n",
    "\n",
    "After setting up our Job schedule, we'll want to set up alerts for our job.\n",
    "\n",
    "Click on the **Settings** tab at the top of the screen.\n",
    "\n",
    "<img src=\"https://files.training.databricks.com/images/idbml/job-5.png\">\n",
    "\n",
    "#### Step 6\n",
    "\n",
    "On the Settings page, you can set up things like alerts and permissions.\n",
    "\n",
    "In this case, we've set up our Job to send us an email alert in the case of the Job failing. You can also set up alerts for when your Job starts and succeeds.\n",
    "\n",
    "<img alt=\"Side Note\" title=\"Side Note\" style=\"vertical-align: text-bottom; position: relative; height:1.75em; top:0.05em; transform:rotate(15deg)\" src=\"https://files.training.databricks.com/static/images/icon-note.webp\"/> If you're working on a team, you'll want to be sure your team members have the appropriate permissions to work with your Job and the corresponding notebook!\n",
    "\n",
    "<img src=\"https://files.training.databricks.com/images/idbml/job-6.png\">\n",
    "\n",
    "#### Step 7\n",
    "\n",
    "At this point, our Job should be set up to run each month!\n",
    "\n",
    "However, we recommend running your Job immediately to verify that all works as expected.\n",
    "\n",
    "To do this, click on the **Runs** tab at the top of the page and then click on **Run Now**.\n",
    "\n",
    "<img src=\"https://files.training.databricks.com/images/idbml/job-7.png\">\n",
    "\n",
    "#### Step 8\n",
    "\n",
    "At this point, you should see the Run under the Active Runs section. Click on the **View Details** button.\n",
    "\n",
    "<img src=\"https://files.training.databricks.com/images/idbml/job-8.png\">\n",
    "\n",
    "#### Step 9\n",
    "\n",
    "This will show you the path for your Job. In this case, we just have one task. You can click on the task to see the running notebook.\n",
    "\n",
    "<img src=\"https://files.training.databricks.com/images/idbml/job-9.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "457d32a5-ada0-4f52-a98a-be09dd4ce71b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "-sandbox\n",
    "&copy; 2021 Databricks, Inc. All rights reserved.<br/>\n",
    "Apache, Apache Spark, Spark and the Spark logo are trademarks of the <a href=\"http://www.apache.org/\">Apache Software Foundation</a>.<br/>\n",
    "<br/>\n",
    "<a href=\"https://databricks.com/privacy-policy\">Privacy Policy</a> | <a href=\"https://databricks.com/terms-of-use\">Terms of Use</a> | <a href=\"http://help.databricks.com/\">Support</a>"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "IDBML 06 - Scheduling a Machine Learning Workflow",
   "notebookOrigID": 3350865296187837,
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
